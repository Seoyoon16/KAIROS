{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcaca607",
   "metadata": {},
   "source": [
    "### SLP로 논리 게이트 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e3fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747b23c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퍼셉트론\n",
    "class Perceptron:\n",
    "    def __init__(self, N, alpha):# 생성자\n",
    "        # 가중치 초기화\n",
    "        self.W = np.random.randn(N+1) / np.sqrt(N) # bias 값까지 N+1개\n",
    "\n",
    "        # 학습률(learning rate) alpha 초기화\n",
    "        self.alpha = alpha\n",
    "\n",
    "\n",
    "    def step(self, x):  # 활성화 함수 - 계단 함수(step function)\n",
    "        if x > 0:\n",
    "          return 1\n",
    "        else: return 0\n",
    "\n",
    "    def fit(self, X, y, epochs = 10):\n",
    "        # X 데이터에 바이어스 항목을 추가. np.ones로 1로 채워진 열을 X에 추가함.\n",
    "        X = np.c_[X, np.ones(X.shape[0])] # 행렬 붙이기\n",
    "\n",
    "        # 지정된 에포크 수만큼 반복 학습.\n",
    "        for epoch in range(epochs):\n",
    "             # X의 각 샘플과 y의 타겟 레이블에 대해 반복.\n",
    "            for (x, target) in zip(X, y):\n",
    "                # self.W :계수 x: AND 논리 입력값 x1 x2\n",
    "                p = self.step(np.dot(x, self.W))\n",
    "\n",
    "                # 예측값 p와 실제 타겟 값이 다르면 가중치를 업데이트.\n",
    "                if p != target: # 같지 않으면 역전파법에 의해서 계수를 업데이트 하기\n",
    "                    # 오류를 계산.\n",
    "                    error = p - target\n",
    "                    # 가중치 업데이트.\n",
    "                    self.W += -self.alpha * error * x\n",
    "\n",
    "    def predict(self, X):  # 예측 메서드\n",
    "        # X를 최소 2차원 배열로 변환.\n",
    "        X = np.atleast_2d(X)\n",
    "\n",
    "        # X에 바이어스 항목 추가.\n",
    "        X = np.c_[X, np.ones(1)]\n",
    "\n",
    "        # 예측을 수행. 가중치와 입력값의 점곱을 계산 후 활성화 함수 적용.\n",
    "        p = self.step(np.dot(X, self.W)) # 여기의 self.W는 이미 트레이닝 이 끝난 상태 즉 추론파일\n",
    "        print(p)\n",
    "        print('------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab9f742",
   "metadata": {},
   "source": [
    "AND 게이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28549696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성\n",
    "per1 = Perceptron(2, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cac60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = np.array([[0], [0], [0], [1]]) # label\n",
    "\n",
    "#학습하기\n",
    "per1.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12162b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# 예측 \n",
    "# flase and false\n",
    "x = np.array([0,0])\n",
    "per1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e84560c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# true and false\n",
    "x = np.array([1,0])\n",
    "per1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0dc5a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# false and true\n",
    "x = np.array([0,1])\n",
    "per1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70043c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# true and true\n",
    "x = np.array([1,1])\n",
    "per1.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3792d45",
   "metadata": {},
   "source": [
    "XOR 게이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edf79adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성\n",
    "per2 = Perceptron(2, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e990b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# 학습하기\n",
    "per2.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "262d1b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "# false xor false\n",
    "x = np.array([0,0])\n",
    "per2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59437282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# true xor false\n",
    "x = np.array([1,0])\n",
    "per2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44bb0e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# false xor true\n",
    "x = np.array([0,1])\n",
    "per2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eea34216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# true xor true\n",
    "x = np.array([1,1])\n",
    "per2.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234ac564",
   "metadata": {},
   "source": [
    "xor 결과가 예상대로 나오지 않음 > xor문제는 비선형문제이기 때문에 SLP로 해결 불가"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08f3946c",
   "metadata": {},
   "source": [
    "활성화 함수 : \n",
    "SLP에서는 주로 단층의 퍼셉트론이기 때문에 보통 계단 함수(Step Function)와 같은 간단한 활성화 함수를 사용 - 이진 분류 or 선형분류\n",
    "MLP에서는 다층의 퍼셉트론으로 비선형 문제를 해결하기 위해 여러 층에 걸쳐 복잡한 활성화 함수 사용. 대표적인 활성화 함수로는 시그모이드(Sigmoid), 하이퍼볼릭 탄젠트(Tanh), ReLU(Rectified Linear Unit) 등이 있음"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13924d3c",
   "metadata": {},
   "source": [
    "단일 층 퍼셉트론 : \n",
    "활성화 함수 없이 순전파만 사용하는 경우, 퍼셉트론은 선형 분리가 가능한 문제만 다룰 수 있음\n",
    "활성화 함수가 없으면 단층 퍼셉트론의 출력이 입력의 선형 조합으로 제한되기 때문\n",
    "비선형 문제를 다루기 위해서는 활성화 함수가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f04950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae216ff8",
   "metadata": {},
   "source": [
    "### MLP로 논리 게이트 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c85a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers, alpha=0.1):\n",
    "        # 생성자: 신경망 초기화\n",
    "        # alpha: 학습률\n",
    "        self.W = [] # 가중치를 저장할 리스트\n",
    "\n",
    "        self.layers = layers  # list [ 2, 2, 2, 1]\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # 가중치 초기화: 입력 레이어부터 마지막 은닉 레이어까지의 가중치를 초기화\n",
    "        for i in np.arange(0, len(layers) - 2): # 마지막 레이어는 가중치 적용x\n",
    "          w = np.random.randn(layers[i]+1, layers[i+1]+1)\n",
    "          self.W.append(w/np.sqrt(layers[i]))\n",
    "\n",
    "        # 마지막 은닉층에서 출력층으로의 가중치를 초기화합니다., 마지막 hidden - out 사이의 계수\n",
    "        w = np.random.randn(layers[-2]+1, layers[-1])\n",
    "        self.W.append(w/np.sqrt(layers[-2]))\n",
    "\n",
    "\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        # 시그모이드(로지스틱스) 활성화 함수: 신경망의 각 노드에서 사용\n",
    "\n",
    "        return 1.0/(1+np.exp(-x))\n",
    "\n",
    "    def sigmoid_deriv(self, x):\n",
    "        # 시그모이드 활성화 함수의 미분: 이는 역전파 시 그래디언트(기울기)를 계산할 때 사용\n",
    "\n",
    "        return x*(1-x)\n",
    "\n",
    "    # 신경망을 학습시키는 메서드입니다.\n",
    "    # 입력 X = np.array([[ 0,0], [ 0,1], [1,0], [0,0]])\n",
    "    # 타겟 y = np.array([[0], [1], [1], [0]])\n",
    "    # epochs: 학습을 위해 데이터셋을 반복할 횟수입니다.\n",
    "    def fit(self, X, y, epochs=1000):\n",
    "        # 입력 데이터에 바이어스를 위한 1 추가\n",
    "        X = np.c_[X, np.ones((X.shape[0]))]\n",
    "\n",
    "        for epoch in np.arange(0,epochs):\n",
    "          for (x, target) in zip(X,y):\n",
    "            self.fit_partial(x,target)\n",
    "\n",
    "\n",
    "    def fit_partial(self, x, y):\n",
    "        # 부분 학습 메서드: x는 단일 데이터 샘플, y는 해당 타겟 레이블\n",
    "        A = [np.atleast_2d(x)]\n",
    "\n",
    "        # 순전파 단계: 입력 데이터가 네트워크를 통해 전파되면서 각 레이어의 출력 계산\n",
    "        for  layers in np.arange(0, len(self.W)):\n",
    "          net = A[layers].dot(self.W[layers])\n",
    "          out = self.sigmoid(net)\n",
    "          A.append(out)\n",
    "\n",
    "        # 역전파 단계: 신경망의 출력과 실제 타겟 값의 차이를 계산합니다.\n",
    "        error = A[-1] - y\n",
    "\n",
    "        # 오류의 시그모이드 미분값을 사용하여 오류 신호 계산\n",
    "        # 그래디언트\n",
    "        D =[error * self.sigmoid_deriv(A[-1])]\n",
    "\n",
    "        # 모든 층에 대해 역전파를 수행합니다. 출력층부터 시작하여 입력층 방향으로 진행합니다.\n",
    "        for  layers in np.arange(len(A) -2, 0, -1):\n",
    "          delta = D[-1].dot(self.W[layers].T)\n",
    "          delta = delta* self.sigmoid_deriv(A[layers])\n",
    "          D.append(delta)\n",
    "\n",
    "\n",
    "        # D 리스트를 뒤집습니다. 이렇게 하여 입력층에 가까운 오류부터 시작하게 됩니다.\n",
    "        D = D[::-1]\n",
    "\n",
    "        # 가중치 업데이트: 모든 레이어에 대해 가중치를 업데이트합니다.\n",
    "        for layer in np.arange(0, len(self.W)):\n",
    "          self.W[layer] += -self.alpha *  A[layer].T.dot(D[layer])\n",
    "\n",
    "\n",
    "    # 예측 메서드: 새로운 데이터에 대한 예측을 수행합니다.\n",
    "    def predict(self, X):  # X = [0 1]\n",
    "        # 입력 데이터를 최소 2차원 배열로 변환합니다.\n",
    "        p = np.atleast_2d(X)\n",
    "\n",
    "        # 바이어스를 위한 1을 추가합니다.\n",
    "        p = np.c_[p, np.ones((p.shape[0]))]\n",
    "\n",
    "        # 신경망을 통해 순전파를 수행하여 예측 결과를 계산합니다.\n",
    "        for layer in np.arange(0, len(self.W)):\n",
    "            p = self.sigmoid(np.dot(p, self.W[layer]))\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84ec2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성 : 1 hidden layer, learning rate 0.5\n",
    "nn = NeuralNetwork([2, 2, 1], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bdf6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ 0,0], [ 0,1], [1,0], [1,1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# 학습 - 역전파 사용\n",
    "nn.fit(X,y,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1225ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.004848633565687469 0\n",
      "1 0.9970251615522081 1\n",
      "1 0.9939909879107264 1\n",
      "0 0.006357017912846011 0\n"
     ]
    }
   ],
   "source": [
    "# 예측 - 순전파\n",
    "for (x, target) in zip(X,y):\n",
    "  pred = nn.predict(x)[0][0]\n",
    "  step  = 1 if pred > 0.5 else 0\n",
    "  print(target[0], pred,step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6540235",
   "metadata": {},
   "source": [
    "값이 예상대로 나오는 것을 확인 가능"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
